
optimizer:
  _partial_: true
  _target_: torch.optim.AdamW
  betas: [0.8, 0.99]
  lr: 0.0001
  weight_decay: 0.001

scheduler:
  _partial_: true
  _target_: utils.scheduler.WarmupCosineLR
  warmup_steps: 2000
  total_steps: 1000000
  min_lr: 0.00001

optimizer_d:
  _partial_: true
  _target_: torch.optim.AdamW
  betas: [0.8, 0.99]
  lr: 0.0002
  weight_decay: 0.001

scheduler_d:
  _partial_: true
  _target_: utils.scheduler.WarmupCosineLR
  warmup_steps: 2000
  total_steps: 1000000
  min_lr: 0.00001